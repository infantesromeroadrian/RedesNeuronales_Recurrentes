{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neuronales Recurrentes - Clasificación de Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezaremos trabajando con el conjunto de datos de audio '16000_pcm_speeches', el cual contiene subcarpetas para cada orador. Este ejercicio se centrará en la clasificación de audio utilizando Redes Neuronales Recurrentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos son los pasos generales que seguiremos:\n",
    "\n",
    "Preprocesamiento de datos: Cargar y procesar los archivos de audio, ajustarlos a la misma longitud si es necesario.\n",
    "Preparación de los datos: Dividir los datos en conjuntos de entrenamiento y prueba, convertir las etiquetas en una forma que pueda ser utilizada por la red neuronal.\n",
    "Construcción del modelo: Crear la arquitectura de la Red Neuronal Recurrente utilizando Keras o una biblioteca similar.\n",
    "Entrenamiento del modelo: Entrenar el modelo en el conjunto de datos de entrenamiento, observar la precisión y la pérdida durante el entrenamiento.\n",
    "Evaluación del modelo: Probar el modelo en el conjunto de datos de prueba para evaluar su rendimiento.\n",
    "Interpretación de los resultados: Analizar los resultados y determinar cómo se podría mejorar el modelo o el preprocesamiento de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-23T15:36:11.182283Z",
     "start_time": "2023-06-23T15:36:11.005304Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importar librerías\n",
    "\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-23T15:36:19.605835Z",
     "start_time": "2023-06-23T15:36:11.185419Z"
    }
   },
   "outputs": [],
   "source": [
    "# directorio de datos\n",
    "DATA_DIR = '16000_pcm_speeches'\n",
    "\n",
    "# lista para guardar los datos de audio y las etiquetas\n",
    "audio_data = []\n",
    "labels = []\n",
    "\n",
    "# recorrer todas las subcarpetas dentro de la carpeta de datos\n",
    "for speaker in os.listdir(DATA_DIR):\n",
    "    speaker_dir = os.path.join(DATA_DIR, speaker)\n",
    "\n",
    "    # asegúrate de que es un directorio\n",
    "    if os.path.isdir(speaker_dir):\n",
    "\n",
    "        # recorrer todos los archivos de audio en la carpeta\n",
    "        for file_name in os.listdir(speaker_dir):\n",
    "            # cargar el archivo de audio\n",
    "            file_path = os.path.join(speaker_dir, file_name)\n",
    "            audio, sr = librosa.load(file_path)\n",
    "\n",
    "            # ajustar la longitud del audio a 1 segundo (16000 muestras)\n",
    "            if len(audio) < sr:\n",
    "                audio = np.pad(audio, (0, sr - len(audio)))\n",
    "            elif len(audio) > sr:\n",
    "                audio = audio[:sr]\n",
    "\n",
    "            # guardar el audio y la etiqueta\n",
    "            audio_data.append(audio)\n",
    "            labels.append(speaker)\n",
    "\n",
    "# convertir a numpy arrays\n",
    "audio_data = np.array(audio_data)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código recorre todas las subcarpetas en el directorio de datos, que se asume que son los nombres de los oradores. Carga cada archivo de audio y ajusta la longitud del audio a exactamente 1 segundo (o 16000 muestras, que es la frecuencia de muestreo de los audios). Los datos de audio y las etiquetas se guardan en listas, que luego se convierten en arrays de numpy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este paso, dividiremos nuestros datos en un conjunto de entrenamiento y un conjunto de prueba. Además, codificaremos nuestras etiquetas de texto (los nombres de los oradores) en un formato que la red neuronal pueda entender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-23T15:36:24.538865Z",
     "start_time": "2023-06-23T15:36:19.608340Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-23 17:36:19.757372: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Preparación de los datos\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# codificar las etiquetas de texto a números\n",
    "le = LabelEncoder()\n",
    "labels_encoded = le.fit_transform(labels)\n",
    "\n",
    "# convertir las etiquetas a codificación one-hot\n",
    "labels_onehot = to_categorical(labels_encoded)\n",
    "\n",
    "# dividir los datos en entrenamiento y prueba\n",
    "x_train, x_test, y_train, y_test = train_test_split(audio_data, labels_onehot, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este código, utilizamos la clase LabelEncoder de scikit-learn para convertir las etiquetas de texto a números, y luego convertimos estos números a una representación \"one-hot\" utilizando la función to_categorical de Keras. La representación one-hot es una matriz donde todos los elementos son 0, excepto uno que es 1, y se utiliza comúnmente para representar variables categóricas en machine learning.\n",
    "\n",
    "Después, utilizamos la función train_test_split de scikit-learn para dividir los datos en un conjunto de entrenamiento (80% de los datos) y un conjunto de prueba (20% de los datos)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para clasificar los audios, vamos a utilizar una Red Neuronal Recurrente (RNN). Las RNN son especialmente adecuadas para datos secuenciales como el audio. En este caso, vamos a utilizar una variante de RNN llamada Long Short-Term Memory (LSTM), que es capaz de aprender dependencias a largo plazo en los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-23T15:36:24.824249Z",
     "start_time": "2023-06-23T15:36:24.538317Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 128)               66560     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 7)                 903       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67,463\n",
      "Trainable params: 67,463\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Construcción del modelo\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# construir el modelo\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(sr, 1)))\n",
    "model.add(Dense(len(np.unique(labels)), activation='softmax'))\n",
    "\n",
    "# compilar el modelo\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# imprimir un resumen del modelo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código construye un modelo secuencial en Keras, que es un tipo de modelo que se compone de una pila de capas. La primera capa es una capa LSTM con 128 unidades. La forma de entrada de esta capa es (sr, 1), donde sr es la frecuencia de muestreo de los audios (16000 en este caso). La última capa es una capa densa con tantas unidades como oradores únicos hay en los datos, y utiliza la activación softmax, que es común para problemas de clasificación multiclase.\n",
    "\n",
    "Después de construir el modelo, lo compilamos con la función de pérdida de entropía cruzada categórica (que es utilizada para problemas de clasificación multiclase), el optimizador Adam, y pedimos que se registre la precisión durante el entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El entrenamiento de un modelo de machine learning implica alimentarlo con datos y dejar que ajuste sus parámetros para minimizar su error de predicción. En este caso, vamos a entrenar nuestro modelo con los datos de entrenamiento que preparamos anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-06-23T15:36:24.827712Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "114/188 [=================>............] - ETA: 14:44 - loss: 1.6708 - accuracy: 0.1872"
     ]
    }
   ],
   "source": [
    "# Entrenamiento del modelo\n",
    "\n",
    "# remodelar los datos para que sean aceptados por la capa LSTM\n",
    "x_train = x_train.reshape(x_train.shape[0], sr, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], sr, 1)\n",
    "\n",
    "# entrenar el modelo\n",
    "history = model.fit(x_train, y_train,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remodelamos nuestros datos para que tengan una dimensión adicional. Esto se debe a que la capa LSTM espera datos de entrada en forma de 3D (muestras, pasos de tiempo, características), mientras que nuestros datos son 2D en este momento.\n",
    "\n",
    "Luego, llamamos a la función fit en nuestro modelo, que es la función que realmente entrena el modelo. Le pasamos nuestros datos de entrenamiento y nuestras etiquetas, especificamos nuestros datos de prueba como datos de validación (para que la función fit calcule la precisión y la pérdida en los datos de prueba en cada época), y especificamos que queremos entrenar por 10 épocas con un tamaño de lote de 32.\n",
    "\n",
    "Una época es una pasada completa a través de todos los datos de entrenamiento, y el tamaño de lote es el número de muestras que el modelo ve antes de actualizar sus parámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Evaluación del modelo\n",
    "\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(f'Test loss: {loss}')\n",
    "print(f'Test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya teeemos un modelo entrenado, y podemos evaluar su rendimiento en los datos de prueba. En este caso, obtenemos una precisión de alrededor del 25%, lo cual no es muy bueno. Esto se debe a que el conjunto de datos los audios de los diferentes oradores son muy similares entre sí. Sin embargo, este modelo puede ser mejorado con más datos y más capas LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Vamos a observar una de las predicciones\n",
    "\n",
    "# obtener una predicción para un audio de prueba\n",
    "\n",
    "y_pred = model.predict(x_test[0].reshape(1, sr, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# obtener el índice de la clase con mayor probabilidad\n",
    "\n",
    "y_pred_class = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# obtener la clase predicha\n",
    "\n",
    "pred_class = le.inverse_transform(y_pred_class)[0]\n",
    "\n",
    "# obtener la clase real\n",
    "\n",
    "real_class = le.inverse_transform(np.argmax(y_test[0], axis=0))[0]\n",
    "\n",
    "print(f'Predicted class: {pred_class}')\n",
    "print(f'Real class: {real_class}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Vamos a dibujar una de las ondas de audio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# seleccionar una muestra de audio\n",
    "sample_audio = audio_data[0]\n",
    "\n",
    "# crear una figura y un eje\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# plotear la onda de sonido\n",
    "ax.plot(sample_audio)\n",
    "\n",
    "# configurar el título y las etiquetas de los ejes\n",
    "ax.set_title('Onda de Sonido')\n",
    "ax.set_xlabel('Tiempo (muestras)')\n",
    "ax.set_ylabel('Amplitud')\n",
    "\n",
    "# mostrar la figura\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Vamos a escuchar una de las muestras de audio\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "# reproducir el audio\n",
    "\n",
    "ipd.Audio(sample_audio, rate=sr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
